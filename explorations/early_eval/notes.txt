[TOP] [Clark] Identify code which can be safely evaluated during static
analysis, ie. `c(1:2, 4:6)`. Example using this information for another part
of analysis

TODO: "eval" is a loaded word, how can we better describe this?
TODO: More use cases for this? Loop invariants?

Early Evaluation
================

Data analysis scripts often begin by loading data, ie:

dframe = read.csv(data.csv)
keepers = c("age", "weight", "blood_pressure")
dframe = dframe[, keepers]

If a subset operation immediately follows the data reading call, then we
only need to read in some of the columns. More generally, the script might not
use all the columns of the data that it reads. For large data sets we can
save time and memory by only reading the columns that are necessary. 
For data coming from a SQL database we can "push" the column selection into
the database. This means the database only passes R the columns that it
needs.

We can often safely evaluate many functions with literal arguments, such as
`c, paste, seq, :, `. The following example shows a case where we would
like to know the value of `first_columns` at code analysis time, because
the user selects columns using R's default names.

first_columns = paste0("V", 1:3)
ss = df[, first_columns]
f(ss)

With these basic examples a user can look and immediately know which
variables are literal constants that can safely be evaluated and known.
For the column selection use case we would like to evaluate as much of
the column selection code as possible so that we can know which columns are
required.

More generally, which expressions in the code can be evaluated based on
literal expressions? We cannot (and do not want to) touch code that does
any of the following:
- reading external data
- random number generation
- drawing plots
- loading packages
- tricky stuff involving environments

(Clark: Just dreaming)
I want something like the idea of the set of R functions which are
mathematically closed under evaluation with literal arguments. That is,
evaluating `f(1L, "A", ...<more literal args>)` has no side effects and
returns something that can be written as a literal vector in R. I mean it
should return something like a scalar/vector or list of literals:
- c(1, 4)
- list(10, c("A", "B"))

The actual data are basic objects, ie. atomic vectors with types "logical",
"integer", etc. More generally it can be a nested list where all the leaf
nodes are basic objects.


Methods
=======

A conservative way to to this is to define a small set of functions that are
considered "safe" to evaluate early. These functions are:

=, <-, c, :, $, [, [[, list, seq

To check if an expression can be evaluated early we collect the names of all the
functions called in the expression. If any are not in this safe list then
this expression cannot be evaluated early. If the expression contains any
other symbols, then again it cannot be evaluated early.

We can combine this with constant propagation. In the following code, we
know that y should be the vector (10, 20, 30).

x = c(10, 20)
y = c(x, 30)

The expression c(x, 30) can be evaluated early by the conservative rule if
and only if x is a known literal. This suggests the approach of an "early
evaluation pass" over a script, where parts of the AST are identified as
either known or unknown. Below is a visual for a mini script, K/U means that
an element of the AST at that point is known/unknown.


col = 100
dframe = read.csv("mydata.csv")
plot(dframe[, col])


col = 100
K     K
# RHS all known => LHS defined

dframe = read.csv("mydata.csv")
U        U        K
# RHS not all known => LHS not defined

plot(dframe[, col])
U    U     K  K

More concisely, we can represent the same information in a data structure
matching the structure of the AST. All we need to do is mark the nodes
which are known. This means that the portion of the AST rooted at that node
is known. This differs slightly from what I wrote above, because 
dframe[, col] would only be marked for the col. The data structure could
be represented as a list of indices corresponding to the code, for example:

K = list(1
       , c(2, 3, 2)
       , c(3, 2, 4)
)

This particular representation helps if we have other code that operates on
indices, for example the column inference code. 

----- Clark: This is maybe too much on implementation.
If the code has been parsed
into an expression with variable name "code" we can evaluate it using this
data structure:

lapply(K, function(ind, .code = code)  ...
-----


This can be thought of as evaluating the code using a tiny version of the R
language containing only the safe functions. When the mini language hits an
"object not found" error it just moves on to the next line. It also must eagerly evaluate
arguments. This is because our main interest is in evaluating c("a", "b") in
the call dframe[, c("a", "b")].

We need to be careful if variables are redefined. For example:

x = 4           # Safe
x = max(1, 2)   # max() not considered safe
y = c(x, 30)    # Now x is unknown

The second line x = max(1, 2) redefines x using a function not considered
safe. So this becomes equivalent to rm(x) in the mini language.

So far we've ignored any subtleties that arise with control flow, non
standard evaluation, or special functions such as rm().

------

A different approach is to identify functions that are "not safe". These
would include data loading, plotting, random numbers, and calls to external
compiled code. This approach seems far more difficult, because we need to
know what the underlying C code does. And we have to examine all the
underlying library code rather than just the code written by the user.
